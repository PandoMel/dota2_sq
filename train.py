# train.py
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3 import PPO
from custom_env import Dota2SquirelEnv
from config import models_path

env = Dota2SquirelEnv()
env = DummyVecEnv([lambda: env])  # –£–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –≤ Vectorized Env

# –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = PPO("MlpPolicy", env, verbose=1, learning_rate=3e-4, n_steps=2048, ent_coef=0.01)

print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
model.learn(total_timesteps=100)
model.save(models_path + "/ppo_squirel_model")
print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
